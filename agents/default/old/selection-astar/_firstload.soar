#### Selection A*

## Supports a variant of A* search using the selection space and associated default rules.
## Requires task-specific rules that compute g(x) + h(x) where 
##  g(x) is the path cost function (cost of search up to a point) and
##  h(x) which is the heuristic estimated cost to the desired state
## This is a variant in that global open and closed lists are not maintained, 
##  although some of the properties of them can be achieved if chunking and episodic memory
##  are used. 
###
## In this implementation, each evaluation in an evaluation space maintains the 
##   estimated cost to the desired state, which is used to bias the selection between evaluate-operator operators.
## These values are updated as results are produced further in the search by passing back updated estimates. 
##
###
##
## To work, each state must have an associated path cost g(x) and h(x). We provide calculations for when
##  the state has a ^current-waypoint (^x ^y) and ^desired.waypoint (^x ^y)
##  it then maintains a ^prior-waypoint (^x ^y), ^path-cost number number, and 
##  on the evaluation (in selection space) it maintains ^estimated-cost (based on geometric distance).
##  It computes total-estimated-cost (path-cost + estimated-cost)
##
##  If there is no current-waypoint and desired.waypoint, task-specific knowledge must maintain the other 
##  structures (prior-waypoint, ...)
## 
## Need to initialize path-cost 0, estimated-cost 0 

## Need to have estimated-cost updated in evaluation as search progresses forward - 
##   Evaluation should hold best total-estimated-cost to date - (from look-aheads)
##    initialized with path cost + estimated cost in subgoal, 
##    How update estimated cost??
